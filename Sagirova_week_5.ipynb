{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peer-graded Assignment: Эксперименты с моделью\n",
    "\n",
    "На прошлой неделе вы поучаствовали в соревновании на kaggle и, наверняка, большинство успешно справилось с прохождением baseline, а значит пора двигаться дальше - заняться оптимизацией модели, провести серию экспериментов и построить сильное финальное решения.\n",
    "\n",
    "В этом задании вам нужно провести ряд эскпериментов, оценить качество полученных в процессе экспериментирования моделей и выбрать лучшее решение. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание будет оцениваться на основании загруженного jupyther notebook и развернутых ответов на поставленные вопросы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mypc\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mypc\\Anaconda2\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:161: UserWarning: pylab import has clobbered these variables: ['shuffle']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn import cross_validation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_encoding(df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    for i in range(40):\n",
    "        integer_encoded = label_encoder.fit_transform(df[df.columns[190 + i]].fillna(0).values)\n",
    "        for j in range(len(df)):\n",
    "            if type(df[df.columns[190 + i]].values[j]) == str:\n",
    "                df[df.columns[190 + i]].values[j] = integer_encoded[j]\n",
    "    df = df.fillna(0.0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def estimation(train_data, test_data):\n",
    "    estimator.fit(train_data[train_data.columns[:230]], train_data['labels'], eval_metric='auc')\n",
    "    xgb_predictions = estimator.predict(test_data[test_data.columns[:230]]) \n",
    "    xgb_predictions_proba = estimator.predict_proba(test_data[test_data.columns[:230]]).transpose()[1]\n",
    "    return xgb_predictions_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>...</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "      <th>Var230</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3052.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>vr93T2a</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>xwM2aC7IdeMC0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1813.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6hQ9lNX</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELof</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>catzS2D</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>ZI9m</td>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1533.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>e4lqvY0</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>686.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>MAz3HNj</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WqMG</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var1  Var2  Var3  Var4  Var5    Var6  Var7  Var8  Var9  Var10   ...    \\\n",
       "0   NaN   NaN   NaN   NaN   NaN  3052.0   NaN   NaN   NaN    NaN   ...     \n",
       "1   NaN   NaN   NaN   NaN   NaN  1813.0   7.0   NaN   NaN    NaN   ...     \n",
       "2   NaN   NaN   NaN   NaN   NaN  1953.0   7.0   NaN   NaN    NaN   ...     \n",
       "3   NaN   NaN   NaN   NaN   NaN  1533.0   7.0   NaN   NaN    NaN   ...     \n",
       "4   NaN   NaN   NaN   NaN   NaN   686.0   7.0   NaN   NaN    NaN   ...     \n",
       "\n",
       "    Var222      Var223  Var224  Var225  Var226   Var227         Var228  \\\n",
       "0  vr93T2a  LM8l689qOp     NaN     NaN    fKCe  02N6s8f  xwM2aC7IdeMC0   \n",
       "1  6hQ9lNX  LM8l689qOp     NaN    ELof    xb3V     RAYp        55YFVY9   \n",
       "2  catzS2D  LM8l689qOp     NaN     NaN    FSa2     ZI9m  ib5G6X1eUxUn6   \n",
       "3  e4lqvY0  LM8l689qOp     NaN     NaN    xb3V     RAYp  F2FyR07IdsN7I   \n",
       "4  MAz3HNj  LM8l689qOp     NaN     NaN    WqMG     RAYp  F2FyR07IdsN7I   \n",
       "\n",
       "   Var229  Var230  labels  \n",
       "0     NaN     NaN      -1  \n",
       "1    mj86     NaN      -1  \n",
       "2    mj86     NaN      -1  \n",
       "3     NaN     NaN       1  \n",
       "4     NaN     NaN      -1  \n",
       "\n",
       "[5 rows x 231 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('orange_small_churn_data.train')\n",
    "labels = pd.read_table('orange_small_churn_labels.train', header = -1, names = [\"labels\"])\n",
    "data['labels'] = labels\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = pd.read_csv('orange_small_churn_data.train')\n",
    "labels = pd.read_table('orange_small_churn_labels.train', header = -1, names = [\"labels\"])\n",
    "encoded_data['labels'] = labels\n",
    "encoded_data = label_encoding(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Начнем с простого. Давайте оценим как много объектов действительно нужно для построения качественной модели. Для обучения доступна достаточно большая выборка и может так оказаться, что начиная с некоторого момента рост размера обучающей выборки перестает влиять на качество модели. Постройте кривые обучения, обучая модель на выборках разного размера начиная с небольшого количество объектов в обучающей выборке и постепенно наращивая её размер с некоторым шагом. Обратите внимание на `sklearn.model_selection.learning_curve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = xgb.XGBClassifier(learning_rate = 0.05, max_delta_step = 1, max_depth = 3, min_child_weight = 20, n_estimators = 500,\n",
    "                              subsample = 0.1)\n",
    "scoring = 'roc_auc'\n",
    "\n",
    "train_encoded_data, test_encoded_data = model_selection.train_test_split(encoded_data, test_size = 0.3)\n",
    "cv = cross_validation.StratifiedKFold(train_encoded_data['labels'], n_folds= 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(estimator, train_encoded_data[train_encoded_data.columns[:230]], \n",
    "                                                        train_encoded_data['labels'], train_sizes = np.linspace(0.1, 1.0, 6),\n",
    "                                                        cv=cv, scoring = scoring)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11faf7f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c22d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Sample size\")\n",
    "plt.ylabel(\"Quality\")\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"b\",\n",
    "    label=\"Train\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"r\",\n",
    "    label=\"Test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Результат\n",
    "При росте размера выборки качество растет и на обучении и, на тесте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Часто несбалансированные по классам выборки приводят к различным проблемам при обучении моделей. Давайте попробуем по-разному обработать выборку, поиграть с распределением объектов по классам и сделать выводы о том, как соотношение классов влияет на качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1\\. Задайте веса объектам так, чтобы соотношение классов с учетом весов объектов изменилось. Попробуйте не менее трёх различных вариантов весов. Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.5396518375\n"
     ]
    }
   ],
   "source": [
    "weight_ratio = float(len(train_encoded_data['labels'][train_encoded_data['labels'] == -1])) / float(len(train_encoded_data['labels'][train_encoded_data['labels'] == 1]))\n",
    "print weight_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.697053061221\n"
     ]
    }
   ],
   "source": [
    "w1 = np.array([1]*train_encoded_data['labels'].shape[0])\n",
    "w1[train_encoded_data['labels'] == -1] = 1\n",
    "w1[train_encoded_data['labels'] == 1] = weight_ratio\n",
    "estimator.fit(train_encoded_data[train_encoded_data.columns[:230]], train_encoded_data['labels'], sample_weight = w1, eval_metric='auc')\n",
    "xgb_predictions = estimator.predict(test_encoded_data[test_encoded_data.columns[:230]]) \n",
    "xgb_predictions_proba = estimator.predict_proba(test_encoded_data[test_encoded_data.columns[:230]]).transpose()[1]\n",
    "print roc_auc_score(test_encoded_data['labels'], xgb_predictions_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.714421117097\n"
     ]
    }
   ],
   "source": [
    "w2 = np.array([1]*train_encoded_data['labels'].shape[0])\n",
    "w2[train_encoded_data['labels'] == -1] = 10.\n",
    "w2[train_encoded_data['labels'] == 1] = 1.\n",
    "estimator.fit(train_encoded_data[train_encoded_data.columns[:230]], train_encoded_data['labels'], sample_weight = w2, eval_metric='auc')\n",
    "xgb_predictions = estimator.predict(test_encoded_data[test_encoded_data.columns[:230]]) \n",
    "xgb_predictions_proba = estimator.predict_proba(test_encoded_data[test_encoded_data.columns[:230]]).transpose()[1]\n",
    "print roc_auc_score(test_encoded_data['labels'], xgb_predictions_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.721636302546\n"
     ]
    }
   ],
   "source": [
    "w3 = np.array([1]*train_encoded_data['labels'].shape[0])\n",
    "w3[train_encoded_data['labels'] == -1] = 1.\n",
    "w3[train_encoded_data['labels'] == 1] = 1.\n",
    "estimator.fit(train_encoded_data[train_encoded_data.columns[:230]], train_encoded_data['labels'], sample_weight = w3, eval_metric='auc')\n",
    "xgb_predictions = estimator.predict(test_encoded_data[test_encoded_data.columns[:230]]) \n",
    "xgb_predictions_proba = estimator.predict_proba(test_encoded_data[test_encoded_data.columns[:230]]).transpose()[1]\n",
    "print roc_auc_score(test_encoded_data['labels'], xgb_predictions_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.717685465256\n"
     ]
    }
   ],
   "source": [
    "w4 = np.array([1]*train_encoded_data['labels'].shape[0])\n",
    "w4[train_encoded_data['labels'] == -1] = 2.\n",
    "w4[train_encoded_data['labels'] == 1] = 1.\n",
    "estimator.fit(train_encoded_data[train_encoded_data.columns[:230]], train_encoded_data['labels'], sample_weight = w4, eval_metric='auc')\n",
    "xgb_predictions = estimator.predict(test_encoded_data[test_encoded_data.columns[:230]]) \n",
    "xgb_predictions_proba = estimator.predict_proba(test_encoded_data[test_encoded_data.columns[:230]]).transpose()[1]\n",
    "print roc_auc_score(test_encoded_data['labels'], xgb_predictions_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ответ\n",
    "Результаты классификации меняются. Качество модели может как повыситься, так и понизиться. Оптимум - соотношение весов классов 1:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2\\. Примените к выборке технологию undersampling: для этого нужно убрать из обучения некоторое количество объектов большего класса таким образом, чтобы соотношение классов изменилось. Попробуйте не менее трёх различных вариантов undersampling (варианты могут отличаться как по количество отфильтрованных объектов, так и по принципу выборка объектов для отсеивания из выборки). Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.694074468879\n"
     ]
    }
   ],
   "source": [
    "# делаем классы равного объема\n",
    "dataChurn = train_encoded_data[train_encoded_data['labels'] == 1]\n",
    "dataNoChurn = train_encoded_data[train_encoded_data['labels'] == -1]\n",
    "countFirst = len(dataChurn)\n",
    "dataChurn = dataChurn.append(dataNoChurn.iloc[:countFirst,:])\n",
    "print roc_auc_score(test_encoded_data['labels'], estimation(dataChurn, test_encoded_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63464559924126762"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# размер класса nonchurn делаем в 2 раза меньше, чем размер класса churn\n",
    "dataChurn2 = train_encoded_data[train_encoded_data['labels'] == 1]\n",
    "dataNoChurn2 = train_encoded_data[train_encoded_data['labels'] == -1]\n",
    "countHalf = len(dataChurn2) / 2\n",
    "dataChurn2 = dataChurn2.append(dataNoChurn2.iloc[:countHalf,:])\n",
    "roc_auc_score(test_encoded_data['labels'], estimation(dataChurn2, test_encoded_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60687247704818803"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# отсеиваем объекты, у которых значение переменной Var228 < 10 (в качетсве примера отсеивания по принципу выбора объетов \n",
    "# из выборки)\n",
    "dataChurn3 = train_encoded_data[train_encoded_data['labels'] == 1]\n",
    "dataNoChurn3 = train_encoded_data[train_encoded_data['labels'] == -1]\n",
    "dataChurn3 = dataChurn3.append(dataNoChurn3[dataNoChurn3[dataNoChurn3.columns[227]] > 10])\n",
    "roc_auc_score(test_encoded_data['labels'], estimation(dataChurn3, test_encoded_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ответ\n",
    "Результаты классификации меняются, причем наиболее высокое качество дает уравнивание объемов классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Теперь перейдем к работе с признаками. Ранее вы реализовали несколько стратегий для обработки пропущенных значений. Сравните эти стратегии между собой с помощью оценки качества моделей кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка пропущенных значений сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71482239160886529"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nan -> среднее значение по признаку\n",
    "enc_data = pd.read_csv('orange_small_churn_data.train')\n",
    "labels = pd.read_table('orange_small_churn_labels.train', header = -1, names = [\"labels\"])\n",
    "enc_data['labels'] = labels\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for i in range(40):\n",
    "    integer_encoded = label_encoder.fit_transform(enc_data[enc_data.columns[190 + i]].fillna(0.).values)\n",
    "    for j in range(len(enc_data)):\n",
    "        if type(enc_data[enc_data.columns[190 + i]].values[j]) == str:\n",
    "            enc_data[enc_data.columns[190 + i]].values[j] = integer_encoded[j]\n",
    "\n",
    "            \n",
    "for i in range(230):\n",
    "    enc_data[enc_data.columns[i]] = enc_data[enc_data.columns[i]].fillna(enc_data[enc_data.columns[i]].mean())\n",
    "    \n",
    "    \n",
    "Xy_train, Xy_test = model_selection.train_test_split(enc_data, test_size=0.3)\n",
    "\n",
    "roc_auc_score(Xy_test['labels'], estimation(Xy_train, Xy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72203436935712084"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nan -> мода (если мода = Nan, то Nan -> 0) \n",
    "labels = pd.read_table('orange_small_churn_labels.train', header = -1, names = [\"labels\"])\n",
    "enc_data['labels'] = labels\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for i in range(40):\n",
    "    integer_encoded = label_encoder.fit_transform(enc_data[enc_data.columns[190 + i]].fillna(0.).values)\n",
    "    for j in range(len(enc_data)):\n",
    "        if type(enc_data[enc_data.columns[190 + i]].values[j]) == str:\n",
    "            enc_data[enc_data.columns[190 + i]].values[j] = integer_encoded[j]\n",
    "\n",
    "            \n",
    "for i in range(230):\n",
    "    enc_data[enc_data.columns[i]] = enc_data[enc_data.columns[i]].fillna(enc_data[enc_data.columns[i]].mode())\n",
    "    \n",
    "    \n",
    "Xy_train, Xy_test = model_selection.train_test_split(enc_data, test_size=0.3)\n",
    "\n",
    "roc_auc_score(Xy_test['labels'], estimation(Xy_train, Xy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7258162460419193"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nan -> 0\n",
    "labels = pd.read_table('orange_small_churn_labels.train', header = -1, names = [\"labels\"])\n",
    "enc_data['labels'] = labels\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for i in range(40):\n",
    "    integer_encoded = label_encoder.fit_transform(enc_data[enc_data.columns[190 + i]].fillna(0.).values)\n",
    "    for j in range(len(enc_data)):\n",
    "        if type(enc_data[enc_data.columns[190 + i]].values[j]) == str:\n",
    "            enc_data[enc_data.columns[190 + i]].values[j] = integer_encoded[j]\n",
    "\n",
    "            \n",
    "for i in range(230):\n",
    "    enc_data[enc_data.columns[i]] = enc_data[enc_data.columns[i]].fillna(0.)\n",
    "    \n",
    "    \n",
    "Xy_train, Xy_test = model_selection.train_test_split(enc_data, test_size=0.3)\n",
    "\n",
    "roc_auc_score(Xy_test['labels'], estimation(Xy_train, Xy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ответ\n",
    "Результаты классификации меняются. Наиболее высокое качество дает вариант замены nan на нуль."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Также вы уже реализовали несколько стратегий для обработки категориальных признаков. Сравните эти стратегии между собой с помощью оценки качества моделей по кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка категориальных признаков сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('orange_small_churn_data.train')\n",
    "raw_labels = pd.read_table('orange_small_churn_labels.train', header = -1, names = [\"labels\"])\n",
    "raw_data['labels'] = raw_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72649029117486286"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encoding\n",
    "le_data = raw_data\n",
    "label_encoder = LabelEncoder()\n",
    "for i in range(40):\n",
    "    integer_encoded = label_encoder.fit_transform(le_data[le_data.columns[190 + i]].fillna(0).values)\n",
    "    for j in range(len(le_data)):\n",
    "        if type(le_data[le_data.columns[190 + i]].values[j]) == str:\n",
    "            le_data[le_data.columns[190 + i]].values[j] = integer_encoded[j]\n",
    "le_data = le_data.fillna(0.0)\n",
    "\n",
    "train_le_data, test_le_data = model_selection.train_test_split(le_data, test_size = 0.3)\n",
    "\n",
    "roc_auc_score(test_le_data['labels'], estimation(train_le_data, test_le_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71987739265128248"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequency Encoding\n",
    "fr_data = raw_data\n",
    "\n",
    "for i in range(40):\n",
    "    curr_col = fr_data[fr_data.columns[190 + i]]\n",
    "    counter = Counter(curr_col.values)\n",
    "    for j in range(len(curr_col)):\n",
    "        if type(curr_col.values[j]) == str:\n",
    "            curr_col.values[j] = 1.0 * counter[curr_col.values[j]] / len(curr_col)\n",
    "\n",
    "fr_data = fr_data.fillna(0.0)\n",
    "\n",
    "train_fr_data, test_fr_data = model_selection.train_test_split(fr_data, test_size = 0.3)\n",
    "\n",
    "roc_auc_score(test_fr_data['labels'], estimation(train_fr_data, test_fr_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ответ\n",
    "Label encoding эффективнее Frequency encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Все ли признаки оказались полезными для построения моделей? Проведите процедуру отбора признаков, попробуйте разные варианты отбора (обратите внимание на модуль `sklearn.feature_selection`). Например, можно выбрасывать случайные признаки или строить отбор на основе l1-регуляризации - отфильтровать из обучения признаки, которые получат нулевой вес при построении регрессии с l1-регуляризацией (`sklearn.linear_model.Lasso`). И всегда можно придумать что-то своё=) Попробуйте как минимум 2 различные стратегии, сравните результаты. Помог ли отбор признаков улучшить качество модели? Поясните свой ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices1 = np.argsort(estimator.feature_importances_)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of features: ', 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mypc\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\mypc\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.781253278255\n",
      "('Number of features: ', 20)\n",
      "0.782473012805\n",
      "('Number of features: ', 50)\n",
      "0.780898779631\n"
     ]
    }
   ],
   "source": [
    "train_df = train_le_data[train_le_data.columns[:230]]\n",
    "test_df = test_le_data[test_le_data.columns[:230]]\n",
    "for i in [10, 20, 50]:\n",
    "    print('Number of features: ', i)\n",
    "    train_le_data_selection = train_df[train_df.columns[indices1[0:i]]]\n",
    "    train_le_data_selection['labels'] = train_le_data['labels']\n",
    "    test_le_data_selection = test_df[test_df.columns[indices1[0:i]]]\n",
    "    test_le_data_selection['labels'] = test_le_data['labels']\n",
    "    print roc_auc_score(test_fr_data_selection['labels'], estimation(train_le_data_selection, test_le_data_selection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mypc\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\mypc\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.781230702996\n"
     ]
    }
   ],
   "source": [
    "train_df = train_le_data[train_le_data.columns[:230]]\n",
    "test_df = test_le_data[test_le_data.columns[:230]]\n",
    "\n",
    "lasso = linear_model.Lasso(alpha = 0.001)\n",
    "lasso.fit(train_df, train_le_data['labels'])\n",
    "lasso_indices = np.argsort(lasso.coef_[lasso.coef_ != 0])\n",
    "\n",
    "train_le_data_selection = train_df[train_df.columns[lasso_indices]]\n",
    "train_le_data_selection['labels'] = train_le_data['labels']\n",
    "test_le_data_selection = test_df[test_df.columns[lasso_indices]]\n",
    "test_le_data_selection['labels'] = test_le_data['labels']\n",
    "print roc_auc_score(test_fr_data_selection['labels'], estimation(train_le_data_selection, test_le_data_selection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ответ\n",
    "При отборе даже 10 признаков наиболее значимых для модели качество падает на - на $2*10^{-3}$. При отборе с помощью l1 - регуляризации качество падает на величину порядка $10^{-3}$. Эффективнее использовать отбор 20 наиболее значимых признаков, чем регуляризацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Подберите оптимальные параметры модели. Обратите внимание, что в зависимости от того, как вы обработали исходные данные, сделали ли балансировку классов, сколько объектов оставили в обучающей выборке и др. оптимальные значения параметров могут меняться. Возьмите наилучшее из ваших решений на текущий момент и проведите процедуру подбора параметров модели (обратите внимание на `sklearn.model_selection.GridSearchCV`) Как подбор параметров повлиял на качество модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Var57     Var113      Var76  Var126     Var134     Var133  Var119  \\\n",
      "2615   5.395001  111370.80  2895912.0     0.0   250844.0  3867615.0  1005.0   \n",
      "4127   5.123264  549944.00   170752.0    22.0   838110.0   373605.0  1035.0   \n",
      "11317  4.087588  232037.20   909128.0     0.0  1016420.0   832850.0  1930.0   \n",
      "25840  3.938475   -7060.84  3456000.0    10.0   353552.0  4715590.0   480.0   \n",
      "29132  0.055330 -101348.00    14968.0     0.0      792.0    49410.0   110.0   \n",
      "\n",
      "           Var81     Var163      Var153   ...      Var125     Var94  Var189  \\\n",
      "2615    60213.00    78966.0  10548800.0   ...     29997.0     450.0     0.0   \n",
      "4127   118212.30  1036800.0   9095760.0   ...      1521.0  104799.0     0.0   \n",
      "11317   86389.20   844458.0   6265760.0   ...    185265.0       0.0   324.0   \n",
      "25840   66232.50   513048.0   9339040.0   ...       738.0  207474.0   258.0   \n",
      "29132    3471.12        0.0     48596.0   ...      2088.0       0.0     0.0   \n",
      "\n",
      "       Var73    Var149  Var140   Var28    Var6   Var13  labels  \n",
      "2615      36   41517.0  4825.0  220.08  1568.0   500.0       1  \n",
      "4127      46       0.0  1200.0  186.64  1127.0  1824.0       1  \n",
      "11317     86  211813.0     0.0  390.48  1645.0    12.0       1  \n",
      "25840    130       0.0    15.0  234.72  2709.0     0.0       1  \n",
      "29132    152   10192.0    10.0  166.56    98.0   392.0       1  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "          Var57    Var113      Var76  Var126    Var134     Var133  Var119  \\\n",
      "35276  6.449477  105297.2  2764800.0   -22.0   40150.0  5218300.0   645.0   \n",
      "27622  0.025208 -345459.2  3460368.0    58.0  398980.0  5055200.0   425.0   \n",
      "536    6.124332  466528.0  2764800.0   -28.0  145048.0  3456000.0   515.0   \n",
      "39189  1.560350  471660.0  2534432.0   -20.0  633608.0  3030845.0   490.0   \n",
      "21715  2.026917 -859064.0        0.0   -28.0       0.0        0.0     0.0   \n",
      "\n",
      "           Var81    Var163      Var153   ...     Var125    Var94  Var189  \\\n",
      "35276  182361.00       0.0  10804120.0   ...        0.0      0.0     0.0   \n",
      "27622   90417.59  392280.0   6924960.0   ...    26739.0    531.0     0.0   \n",
      "536    172889.40       0.0  10357880.0   ...    12780.0  18510.0   336.0   \n",
      "39189  179595.00  475212.0   9546040.0   ...    10557.0    126.0     0.0   \n",
      "21715       0.00       0.0    316804.0   ...        0.0      0.0     0.0   \n",
      "\n",
      "       Var73     Var149  Var140   Var28    Var6   Var13  labels  \n",
      "35276     30   604800.0    10.0  286.96   791.0     0.0       1  \n",
      "27622    156  1813959.0  9515.0  186.64   966.0  8764.0      -1  \n",
      "536       72  1209600.0   200.0  273.60  1071.0    56.0      -1  \n",
      "39189    154   554407.0  1505.0  301.44   623.0  1508.0      -1  \n",
      "21715     12        0.0     0.0  105.04     0.0     0.0      -1  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mypc\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\mypc\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('orange_small_churn_data.train')\n",
    "df_labels = pd.read_table('orange_small_churn_labels.train', header = -1, names = [\"labels\"])\n",
    "df['labels'] = df_labels\n",
    "\n",
    "train_df, test_df = model_selection.train_test_split(df, test_size = 0.3)\n",
    "\n",
    "estimator = xgb.XGBClassifier(learning_rate = 0.05, max_delta_step = 1, max_depth = 3, min_child_weight = 20, n_estimators = 500,\n",
    "                              subsample = 0.1)\n",
    "scoring = 'roc_auc'\n",
    "cv = cross_validation.StratifiedKFold(train_df['labels'], n_folds= 4)\n",
    "\n",
    "\n",
    "w3 = np.array([1]*train_df['labels'].shape[0])\n",
    "w3[train_df['labels'] == -1] = 1.\n",
    "w3[train_df['labels'] == 1] = 1.\n",
    "\n",
    "\n",
    "dataChurn = train_df[train_df['labels'] == 1]\n",
    "dataNoChurn = train_df[train_df['labels'] == -1]\n",
    "countFirst = len(dataChurn)\n",
    "dataChurn = dataChurn.append(dataNoChurn.iloc[:countFirst,:])\n",
    "\n",
    "le_data1 = dataChurn\n",
    "le_data2 = test_df\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for i in range(40):\n",
    "    integer_encoded1 = label_encoder.fit_transform(le_data1[le_data1.columns[190 + i]].fillna(0.).values)\n",
    "    for j in range(len(le_data1)):\n",
    "        if type(le_data1[le_data1.columns[190 + i]].values[j]) == str:\n",
    "            le_data1[le_data1.columns[190 + i]].values[j] = integer_encoded[j]\n",
    "    integer_encoded2 = label_encoder.fit_transform(le_data2[le_data2.columns[190 + i]].fillna(0.).values)\n",
    "    for j in range(len(le_data2)):\n",
    "        if type(le_data2[le_data2.columns[190 + i]].values[j]) == str:\n",
    "            le_data2[le_data2.columns[190 + i]].values[j] = integer_encoded[j]\n",
    "\n",
    "le_data1 = le_data1.fillna(0.)\n",
    "le_data2 = le_data2.fillna(0.)\n",
    "\n",
    "\n",
    "estimator.fit(le_data1[le_data1.columns[:230]], le_data1['labels'], sample_weight = w3, eval_metric='auc')\n",
    "indices1 = np.argsort(estimator.feature_importances_)[::-1]\n",
    "train_df = le_data1[le_data1.columns[:230]]\n",
    "test_df = le_data2[le_data2.columns[:230]]\n",
    "\n",
    "train_df_selection = train_df[train_df.columns[indices1[0:20]]]\n",
    "train_df_selection['labels'] = le_data1['labels']\n",
    "test_df_selection = test_df[test_df.columns[indices1[0:20]]]\n",
    "test_df_selection['labels'] = le_data2['labels']\n",
    "\n",
    "\n",
    "print train_df_selection.head()\n",
    "print test_df_selection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.696985772342\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(train_df_selection[train_df_selection.columns[:20]], train_df_selection['labels'], sample_weight = w3, eval_metric='auc')\n",
    "xgb_predictions = estimator.predict(test_df_selection[test_df_selection.columns[:20]]) \n",
    "xgb_predictions_proba = estimator.predict_proba(test_df_selection[test_df_selection.columns[:20]]).transpose()[1]\n",
    "print roc_auc_score(test_df_selection['labels'], xgb_predictions_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.58183062  0.41816938]\n",
      " [ 0.58606315  0.41393688]\n",
      " [ 0.81797498  0.18202502]\n",
      " ..., \n",
      " [ 0.61155617  0.38844386]\n",
      " [ 0.45347518  0.54652482]\n",
      " [ 0.91211408  0.08788594]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_model = xgb.XGBClassifier()\n",
    "parameters = {'max_depth':[3, 4, 5], 'learning_rate':[0.1, 0.2, 0.3, 0.4, 0.5], 'n_estimators':[10, 50, 100, 200]}\n",
    "model = GridSearchCV(grid_model, parameters, scoring = 'roc_auc')\n",
    "model.fit(train_df_selection[train_df_selection.columns[:20]], train_df_selection['labels'])\n",
    "predicted_proba = model.best_estimator_.predict_proba(test_df_selection[test_df_selection.columns[:20]])\n",
    "print predicted_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ответ\n",
    "Наилучшие параметры модели отличаются от дефолтных:  n_estimators=50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.712404219761\n"
     ]
    }
   ],
   "source": [
    "print roc_auc_score(test_df_selection['labels'],predicted_proba[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Предложите методику оценки того, какие признаки внесли наибольший вклад в модель (например, это могут быть веса в случае регрессии, а также большое количество моделей реализуют метод `feature_importances_` - оценка важности признаков). На основе предложенной методики проанализируйте, какие признаки внесли больший вклад в модель, а какие меньший?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Var57', 0.07692308),\n",
       " ('Var113', 0.088757396),\n",
       " ('Var76', 0.01183432),\n",
       " ('Var126', 0.20414202),\n",
       " ('Var134', 0.0147929),\n",
       " ('Var133', 0.0059171598),\n",
       " ('Var119', 0.020710059),\n",
       " ('Var81', 0.071005918),\n",
       " ('Var163', 0.023668639),\n",
       " ('Var153', 0.035502959),\n",
       " ('Var38', 0.029585799),\n",
       " ('Var125', 0.023668639),\n",
       " ('Var94', 0.023668639),\n",
       " ('Var189', 0.11538462),\n",
       " ('Var73', 0.073964499),\n",
       " ('Var149', 0.0),\n",
       " ('Var140', 0.035502959),\n",
       " ('Var28', 0.065088756),\n",
       " ('Var6', 0.020710059),\n",
       " ('Var13', 0.059171598)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features weights\n",
    "zip(train_df.columns[indices1[0:20]], model.best_estimator_.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ответ\n",
    "Из отобранных 20 признаков все числовые, что показывает их значимость в отличие от категориальных. Наибольший вклад в модель внесли признаки 'Var113', 'Var189' и 'Var126' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Напоследок давайте посмотрим на объекты. На каких объектах достигается наибольшая ошибка классификации? Есть ли межу этими объектами что-то общее? Видны ли какие-либо закономерности? Предположите, почему наибольшая ошибка достигается именно на этих объектах. В данном случае \"наибольшую\" ошибку можно понимать как отнесение объекта с чужому классу с большой долей уверенности (с высокой вероятностью)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,u'The most impotant features for objects with the biggest error')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdYAAAEVCAYAAABdZsRAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMwK5MRqZmZWoP8Pk7AVW/fHJlwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4c659400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_err = pd.DataFrame(test_df_selection[test_df_selection.columns[:20]], columns = train_df.columns[indices1[0:20]])\n",
    "max_err['real_labels'] = test_df_selection['labels'].values\n",
    "max_err['predicted_labels'] = model.best_estimator_.predict(test_df_selection[test_df_selection.columns[:20]])\n",
    "max_err['probability'] = model.best_estimator_.predict_proba(test_df_selection[test_df_selection.columns[:20]])[:,1]\n",
    "plt.hist(max_err[max_err['real_labels'] != max_err['predicted_labels']]['Var113'])\n",
    "plt.hist(max_err[max_err['real_labels'] != max_err['predicted_labels']]['Var189'])\n",
    "plt.hist(max_err[max_err['real_labels'] != max_err['predicted_labels']]['Var126'])\n",
    "plt.legend(['Var113', 'Var189', 'Var126'], bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('The most impotant features for objects with the biggest error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,u'The most impotant features for the whole sample')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdYAAAEVCAYAAABdZsRAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14d309b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(max_err['Var113'])\n",
    "plt.hist(max_err['Var189'])\n",
    "plt.hist(max_err['Var126'])\n",
    "plt.legend(['Var113', 'Var189', 'Var126'], bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('The most impotant features for the whole sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ответ\n",
    "Большая часть ошибок происходит на объектах класса \"churn\". Распределения важнейших признаков похожи друг на друга и в случае объектов с ошибкой и для всей выборки (можно предположить, что эти признаки похожи на признаки объектов класса \"non churn\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. По итогам проведенных экспериментов постройте финальную решение - модель с наилучшим качеством. Укажите, какие преобразования данных, параметры и пр. вы выбрали для построения финальной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mypc\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\mypc\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.719138170009\n"
     ]
    }
   ],
   "source": [
    "# загружаем датасет\n",
    "df = pd.read_csv('orange_small_churn_data.train')\n",
    "df_labels = pd.read_table('orange_small_churn_labels.train', header = -1, names = [\"labels\"])\n",
    "df['labels'] = df_labels\n",
    "\n",
    "train_df, test_df = model_selection.train_test_split(df, test_size = 0.3)\n",
    "\n",
    "# классификатор\n",
    "estimator = xgb.XGBClassifier(learning_rate = 0.05, max_delta_step = 1, max_depth = 3, min_child_weight = 20, n_estimators = 500,\n",
    "                              subsample = 0.1)\n",
    "scoring = 'roc_auc'\n",
    "cv = cross_validation.StratifiedKFold(train_df['labels'], n_folds= 4)\n",
    "\n",
    "# устанавливаем веса модели\n",
    "w3 = np.array([1]*train_df['labels'].shape[0])\n",
    "w3[train_df['labels'] == -1] = 1.\n",
    "w3[train_df['labels'] == 1] = 1.\n",
    "\n",
    "# undersampling\n",
    "dataChurn = train_df[train_df['labels'] == 1]\n",
    "dataNoChurn = train_df[train_df['labels'] == -1]\n",
    "countFirst = len(dataChurn)\n",
    "dataChurn = dataChurn.append(dataNoChurn.iloc[:countFirst,:])\n",
    "\n",
    "le_data1 = dataChurn\n",
    "le_data2 = test_df\n",
    "\n",
    "# label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "for i in range(40):\n",
    "    integer_encoded1 = label_encoder.fit_transform(le_data1[le_data1.columns[190 + i]].fillna(0.).values)\n",
    "    for j in range(len(le_data1)):\n",
    "        if type(le_data1[le_data1.columns[190 + i]].values[j]) == str:\n",
    "            le_data1[le_data1.columns[190 + i]].values[j] = integer_encoded[j]\n",
    "    integer_encoded2 = label_encoder.fit_transform(le_data2[le_data2.columns[190 + i]].fillna(0.).values)\n",
    "    for j in range(len(le_data2)):\n",
    "        if type(le_data2[le_data2.columns[190 + i]].values[j]) == str:\n",
    "            le_data2[le_data2.columns[190 + i]].values[j] = integer_encoded[j]\n",
    "\n",
    "# заполняем nan нулями  \n",
    "le_data1 = le_data1.fillna(0.)\n",
    "le_data2 = le_data2.fillna(0.)\n",
    "\n",
    "# отбор признаков\n",
    "estimator.fit(le_data1[le_data1.columns[:230]], le_data1['labels'], sample_weight = w3, eval_metric='auc')\n",
    "indices1 = np.argsort(estimator.feature_importances_)[::-1]\n",
    "train_df = le_data1[le_data1.columns[:230]]\n",
    "test_df = le_data2[le_data2.columns[:230]]\n",
    "\n",
    "train_df_selection = train_df[train_df.columns[indices1[0:20]]]\n",
    "train_df_selection['labels'] = le_data1['labels']\n",
    "test_df_selection = test_df[test_df.columns[indices1[0:20]]]\n",
    "test_df_selection['labels'] = le_data2['labels']\n",
    "\n",
    "# модель\n",
    "final_model = xgb.XGBClassifier(n_estimators = 50)\n",
    "final_model.fit(train_df_selection[train_df_selection.columns[:20]], train_df_selection['labels'], sample_weight = w3, eval_metric='auc')\n",
    "xgb_predictions = final_model.predict(test_df_selection[test_df_selection.columns[:20]]) \n",
    "xgb_predictions_proba = final_model.predict_proba(test_df_selection[test_df_selection.columns[:20]]).transpose()[1]\n",
    "print roc_auc_score(test_df_selection['labels'], xgb_predictions_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. Подумайте, можно ли еще улучшить модель? Что для этого можно сделать? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Можно избавиться от выбросов, протестировать другие модели. Можно попробовать трансформировать отобранные признаки."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
